# Implementing ASMODEE {#asmodee}

ASMODEE is a new method for detecting recent changes in temporal trends
introduced by Jombart et al. [@Jombart2021-ws] and implemented in the R package
*trendbreaker* [@R-trendbreaker] as the function `asmodee`. Rather than
attempting to estimate significant changes in growth rates or reproduction
numbers, which can usually only be done after changes have been taking place for
a week or two, ASMODEE tries to answer the question: "*Are the last few days
matching what we would expect given the previous trend in the data?*".


```{r echo = FALSE}

cap <- "**Rationale of ASMODEE.** This figure illustrates the key steps of ASMODEE for detecting recent changes in temporal trends."

```

```{r asmodee, fig.align='center', echo=FALSE, fig.cap = cap, out.width = "75%"}
knitr::include_graphics('images/asmodee.png', dpi = NA)
```

To answer this question, ASMODEE implements the following approach (Figure
\@ref(fig:asmodee)):

1. Split the data in two sets: a **testing** set formed by the most 'recent'
   data (typically the last week), and a **fitting** set one used for
   charactering trends on the past few weeks (typically 6 - 10 weeks) prior to
   the testing set.
   
2. Define a range of **candidate models** to characterise temporal trends in the
   **fitting set**.

3. Extrapolate past trends to derive a **95% prediction interval** (**PI**) for the last
   week of data.
   
4. Identify data outside the PI as outliers, suggesting either a slow-down
   (below the PI), or an acceleration (above the PI). In our algorithm for
   defining ELR for countries, we use a criteria of **3 net increases** as a
   sign of acceleration; *net increases* are defined as the number of outliers
   above the PI, minus the number of outliers below the PI, in the last 7 days.

Step 2 is the crucial one to obtain good results. Defining the right set of
**candidate models** to capture past trends is non-trivial, and is also the
non-standard part of implementing ASMODEE, as model-generation is currently not
implemented in *trendbreaker*, and requires *ad-hoc* code. In this chapter, we
provide tips and explanations on how candidate models are generated, and can be
adapted to other data streams.



## A unified interface for linear models

In this section, we outline the general principle of model generation for
ASMODEE.  All models used in ASMODEE use *trending* [@R-trending], which
provides a general interface for different types of statistical models,
including:

* `lm_model`: linear regression, wrapper for `lm`
* `glm_model`: generalized linear models (GLM), wrapper for `glm`
* `glm_nb_model`: negative binomial GLM, wrapper for `MASS:glm.nb`

The advantage of this interface is consitency of behaviours for various
operations, e.g. fitting, predictions, confidence intervals and prediction
intervals.

The formula syntax of these models is the same as in regular models, so the user
should not have new difficulties specifying models with *trending*.
For more information on the package, see the dedicated 
[website](https://www.repidemicsconsortium.org/trending/).

To use `asmodee`, the user needs to provide a `list` of *trending* models. An
example of such a list is provided by `models` in the code below, which
implements different models of cases over time:

* a constant model with Gaussian error
* a linear temporal trend with Gaussian error
* a log-linear temporal trend with Poisson distribution
* a log-linear temporal trend with Negative Binomial distribution

```{r }

library(trending)

models <- list(
  cst = lm_model(cases ~ 1),
  linear = lm_model(cases ~ date),
  poisson = glm_model(cases ~ date, family = poisson),
  nb = glm_nb_model(cases ~ date)
)

```

This assumes the data we will fit these models to will have a `cases` and a
`date` column containing, respectively, the daily case incidence and the
corresponding date as a `Date` object. However, these models would capture only
simple trends (constant, linear, or exponential), and data are typically more
complicated. The following sections illustrate how more flexible models can be
added to the list of candidate models.




## Generating candidate models: general principle 

The approach to generating many candidate models used in `regional_analysis.Rmd`
is to generate `character` strings matching *trending* models definitions (see
previous section) and then using the `eval(parse(text = my_text))` trick to turn
these into actual models. The simplest approach is to:

1. generate text matching the right-hand side of the formula of the different
   models (we later refer to this as **model content**)
   
2. build `character` strings matching model calls using the terms in 1); `sprintf`
   is particularly handy for this part
   
3. transform these `character` strings to actual model calls within a `lapply`



Here is a toy example illustrating the approach:

```{r results = "markup"}

library(trending)

# step 1
mod_content <- c("1", "test", "date", "date + tests")

# step 2
models_txt <- sprintf("glm_model(cases ~ %s, family = poisson)", mod_content)

# step 3
models <- lapply(models_txt, function(e) eval(parse(text = e)))
class(models) # this is a list
length(models) # each component is a model
lapply(models, class) # check classes of each model

```

As the main thing that changes across models is the **model content**, the main
task boils down to generating combinations of predictors to capture different
trends in the data. To this end, we will use `expand.grid`, which creates all
possible combinations of a given set of variables. For instance, to generate all
models which:

* include a `date` effect
* may include a `test` effect
* may include a `weekday` effect
* may include a previous day's incidence as predictor (`cases_lag_1`),
  i.e. autoregressive model
  
We can use:

```{r results = "markup"}

# generate all combinations
mod_content_grid <- expand.grid(c("", "tests"),
                                "date",
                                c("", "weekday"),
                                c("", "cases_lag_1"))
mod_content_grid

# concatenate the columns
mod_content <- apply(mod_content_grid, 1, paste, collapse = " + ")
mod_content

```

We see that `mod_content` contains the relevant model content, with some
issues of additional `+` signs which will need removing. This can be done using
simple regular expressions:

```{r results = "markup"}

## cleanup model content
mod_content <- gsub("(\\+[ ]*)+[ ]*\\+", " + ", mod_content) # +... + -> +
mod_content <- sub("^[ ]*\\+", "", mod_content) # heading +
mod_content <- sub("\\+[ ]*$", "", mod_content) # trailing +
mod_content <- sub("^[ ]+", "", mod_content) # heading spaces
mod_content <- sub("[ ]+$", "", mod_content) # trailing spaces
mod_content <- sub("[ ]+", " ", mod_content) # multiple spaces
mod_content

```

We now have clean model content which can be turned into *trending* models using
the approach illustrated before. In the following sections, we highlight tricks
for capturing specific trends in the data, but all ultimately rely on the
principle illustrated here.




## Capturing difficult trends

In this section, we highlight a few tricks used for capturing non-trivial
temporal trends.

### Periodic fluctuations

Periodic changes are often observed due to either seasonality (over long time
scales for seasonal diseases such as influenza), but are also frequent in the
case of COVID-19 due to reporting artifacts (Figure \@ref(fig:asmodee_periodic). For instance, some countries report
less cases over a weekend, followed by a spike on the following day (*backlog*
effect).


```{r echo = FALSE}

cap <- "**Example of periodicity in COVID-19 data.** This figure illustrates a case of weekly periodicity in raw data (red dots and plain black line) cpatured by ASMODEE (grey dots and model envelope)."

```

```{r asmodee_periodic, fig.align='center', echo=FALSE, fig.cap = cap, out.width = "50%"}
knitr::include_graphics('images/asmodee.png', dpi = NA)
```

Such trends can be captured by different predictors: 

1. a strict `weekend` effect, i.e. a categorical variable distinguishing weekends
  from weekdays
2. a `weekend` effect including a backlog effect, i.e. a categorical variable
  distinguishing weekends, Mondays, and other weekdays
3. a `weekday` effect, i.e. a categorical variable distinguishing each day in the week

At the time of writing, only 2 and 3 are used in the data pipelines. Option 2)
is implemented by the function `day_of_week()` in the *scripts/* folder, also
provided below. Option 3) is implemented in base R by `weekdays`. Both functions
generate categorical variables from a `Date` input; for instance:

```{r }

#' Convert dates to factors
#'
#' This will map a `Date' vector to weekdays, with the following distinction:
#' weekden, monday, of the rest of the week
#'
#' @author Thibaut
#'
#' @param date a vector of `Date`
#' 
day_of_week <- function(date) {
  day_of_week <- weekdays(date)
  out <- vapply(
    day_of_week,
    function(x) {
      if (x %in% c("Saturday", "Sunday")) {
        "weekend"
      } else if (x == "Monday") {
        "monday"
      } else {
        "rest_of_week"
      }
    },
    character(1)
  )
  factor(out, levels = c("rest_of_week", "monday", "weekend"))
} 

# generate some dates for the example
some_dates <- as.Date("2021-02-04") + 0:9
some_dates

# build new variables using dplyr
library(magrittr)
library(dplyr)
tibble(date = some_dates) %>%
  mutate(weekend = day_of_week(date), weekday = weekdays(date))

```


